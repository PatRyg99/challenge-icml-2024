{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Pointcloud-to-Graph Geodesic Lifting Tutorial"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "***\n",
    "This notebook shows how to import a dataset, with the desired lifting, and how to run a neural network using the loaded data.\n",
    "\n",
    "The notebook is divided into sections:\n",
    "\n",
    "- [Loading the dataset](#loading-the-dataset) loads the config files for the data and the desired tranformation, createsa a dataset object and visualizes it.\n",
    "- [Loading and applying the lifting](#loading-and-applying-the-lifting) defines a simple neural network to test that the lifting creates the expected incidence matrices.\n",
    "- [Create and run a simplicial nn model](#create-and-run-a-simplicial-nn-model) simply runs a forward pass of the model to check that everything is working as expected.\n",
    "\n",
    "***\n",
    "***\n",
    "\n",
    "Note that for simplicity the notebook is setup to use a simple graph. However, there is a set of available datasets that you can play with.\n",
    "\n",
    "To switch to one of the available datasets, simply change the *dataset_name* variable in [Dataset config](#dataset-config) to one of the following names:\n",
    "\n",
    "* cocitation_cora\n",
    "* cocitation_citeseer\n",
    "* cocitation_pubmed\n",
    "* MUTAG\n",
    "* NCI1\n",
    "* NCI109\n",
    "* PROTEINS_TU\n",
    "* AQSOL\n",
    "* ZINC\n",
    "***"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports and utilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# With this cell any imported module is reloaded before each cell execution\n",
    "%load_ext autoreload\n",
    "%autoreload 2\n",
    "from modules.data.load.loaders import PointCloudLoader\n",
    "from modules.data.preprocess.preprocessor import PreProcessor\n",
    "from modules.utils.utils import (\n",
    "    describe_data,\n",
    "    load_dataset_config,\n",
    "    load_model_config,\n",
    "    load_transform_config,\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading the Dataset"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Here we just need to spicify the name of the available dataset that we want to load. First, the dataset config is read from the corresponding yaml file (located at `/configs/datasets/` directory), and then the data is loaded via the implemented `Loaders`.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset configuration for gudhi_bunny:\n",
      "\n",
      "{'data_domain': 'pointcloud',\n",
      " 'data_type': 'gudhi',\n",
      " 'data_name': 'gudhi_bunny',\n",
      " 'data_dir': 'datasets/pointcloud/gudhi',\n",
      " 'task': 'regression',\n",
      " 'loss_type': 'mse',\n",
      " 'monitor_metric': 'mae'}\n"
     ]
    }
   ],
   "source": [
    "dataset_name = \"gudhi_bunny\"\n",
    "dataset_config = load_dataset_config(dataset_name)\n",
    "loader = PointCloudLoader(dataset_config)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can then access to the data through the `load()`method:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Dataset only contains 1 sample:\n",
      " - Graph with 35947 vertices and 0 edges.\n",
      " - Features dimensions: [0, 0]\n",
      "\n"
     ]
    }
   ],
   "source": [
    "dataset = loader.load()\n",
    "describe_data(dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Loading and Applying the Lifting"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section we will instantiate the lifting we want to apply to the data. For this example the clique lifting was chosen. For a clique of n nodes the algorithm for $m=3,...,max(n, complex\\_dim)$ will create simplicials for every possible combinations containing m nodes of the clique. $complex\\_dim$ is a parameter of the lifting. This is a deterministic lifting, based on connectivity, that does not modify the initial connectivity of the graph. The problem of extracting all the cliques in a graph is NP-hard, on in some formulaitons NP-complete (clique decision problem). The computational complexity of this algorithm is $O(n^k k^2)$[[1]](https://www.sciencedirect.com/science/article/pii/S0019995885800413), where $n$ is the number of nodes in the graph and $k$ is the highest clique dimension considered.\n",
    "\n",
    "***\n",
    "[[1]](https://www.sciencedirect.com/science/article/pii/S0019995885800413) Cook, S. A. (1985). A taxonomy of problems with fast parallel algorithms. Information and control, 64(1-3), 2-22.\n",
    "***\n",
    "\n",
    "For simplicial complexes creating a lifting involves creating a `SimplicialComplex` object from topomodelx and adding simplices to it using the method `add_simplices_from`. The `SimplicialComplex` class then takes care of creating all the needed matrices.\n",
    "\n",
    "Similarly to before, we can specify the transformation we want to apply through its type and id --the correxponding config files located at `/configs/transforms`. \n",
    "\n",
    "Note that the *tranform_config* dictionary generated below can contain a sequence of tranforms if it is needed.\n",
    "\n",
    "This can also be used to explore liftings from one topological domain to another, for example using two liftings it is possible to achieve a sequence such as: graph -> simplicial complex -> hypergraph. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Transform configuration for pointcloud2graph/geodesic_lifting:\n",
      "\n",
      "{'transform_type': 'lifting',\n",
      " 'transform_name': 'GeodesicLifting',\n",
      " 'feature_lifting': 'ProjectionSum',\n",
      " 'distance': 1.0}\n"
     ]
    }
   ],
   "source": [
    "# Define transformation type and id\n",
    "transform_type = \"liftings\"\n",
    "# If the transform is a topological lifting, it should include both the type of the lifting and the identifier\n",
    "transform_id = \"pointcloud2graph/geodesic_lifting\"\n",
    "\n",
    "# Read yaml file\n",
    "transform_config = {\n",
    "    \"lifting\": load_transform_config(transform_type, transform_id)\n",
    "    # other transforms (e.g. data manipulations, feature liftings) can be added here\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We than apply the transform via our `PreProcesor`:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Processing...\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "958af764df3a416da9b4022638ab80d8",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0/35947 [00:00<?, ?it/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "ename": "ValueError",
     "evalue": "invalid literal for int() with base 10: 'edges'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m lifted_dataset \u001b[38;5;241m=\u001b[39m \u001b[43mPreProcessor\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdataset\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform_config\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mloader\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_dir\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      2\u001b[0m describe_data(lifted_dataset)\n",
      "File \u001b[0;32m~/Documents/UTWENTE/Projects/challenge-icml-2024/modules/data/preprocess/preprocessor.py:32\u001b[0m, in \u001b[0;36mPreProcessor.__init__\u001b[0;34m(self, data_list, transforms_config, data_dir, **kwargs)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list \u001b[38;5;241m=\u001b[39m data_list\n\u001b[1;32m     31\u001b[0m pre_transform \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39minstantiate_pre_transform(data_dir, transforms_config)\n\u001b[0;32m---> 32\u001b[0m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocessed_data_dir\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mNone\u001b[39;49;00m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     33\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39msave_transform_parameters()\n\u001b[1;32m     34\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mload(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_paths[\u001b[38;5;241m0\u001b[39m])\n",
      "File \u001b[0;32m~/anaconda3/envs/virtu-stent/lib/python3.11/site-packages/torch_geometric/data/in_memory_dataset.py:81\u001b[0m, in \u001b[0;36mInMemoryDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m     72\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__init__\u001b[39m(\n\u001b[1;32m     73\u001b[0m     \u001b[38;5;28mself\u001b[39m,\n\u001b[1;32m     74\u001b[0m     root: Optional[\u001b[38;5;28mstr\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     79\u001b[0m     force_reload: \u001b[38;5;28mbool\u001b[39m \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mFalse\u001b[39;00m,\n\u001b[1;32m     80\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[0;32m---> 81\u001b[0m     \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[38;5;21;43m__init__\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mroot\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mtransform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_transform\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpre_filter\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mlog\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     82\u001b[0m \u001b[43m                     \u001b[49m\u001b[43mforce_reload\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     84\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data: Optional[BaseData] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m     85\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices: Optional[Dict[\u001b[38;5;28mstr\u001b[39m, Tensor]] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/virtu-stent/lib/python3.11/site-packages/torch_geometric/data/dataset.py:115\u001b[0m, in \u001b[0;36mDataset.__init__\u001b[0;34m(self, root, transform, pre_transform, pre_filter, log, force_reload)\u001b[0m\n\u001b[1;32m    112\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_download()\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mhas_process:\n\u001b[0;32m--> 115\u001b[0m     \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_process\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/virtu-stent/lib/python3.11/site-packages/torch_geometric/data/dataset.py:260\u001b[0m, in \u001b[0;36mDataset._process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    257\u001b[0m     \u001b[38;5;28mprint\u001b[39m(\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mProcessing...\u001b[39m\u001b[38;5;124m'\u001b[39m, file\u001b[38;5;241m=\u001b[39msys\u001b[38;5;241m.\u001b[39mstderr)\n\u001b[1;32m    259\u001b[0m fs\u001b[38;5;241m.\u001b[39mmakedirs(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir, exist_ok\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[0;32m--> 260\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mprocess\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    262\u001b[0m path \u001b[38;5;241m=\u001b[39m osp\u001b[38;5;241m.\u001b[39mjoin(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mprocessed_dir, \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mpre_transform.pt\u001b[39m\u001b[38;5;124m'\u001b[39m)\n\u001b[1;32m    263\u001b[0m fs\u001b[38;5;241m.\u001b[39mtorch_save(_repr(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mpre_transform), path)\n",
      "File \u001b[0;32m~/Documents/UTWENTE/Projects/challenge-icml-2024/modules/data/preprocess/preprocessor.py:131\u001b[0m, in \u001b[0;36mPreProcessor.process\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Process the data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list \u001b[38;5;241m=\u001b[39m \u001b[43m[\u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43md\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_list\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list)\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Reset cache.\u001b[39;00m\n",
      "File \u001b[0;32m~/Documents/UTWENTE/Projects/challenge-icml-2024/modules/data/preprocess/preprocessor.py:131\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m    129\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mprocess\u001b[39m(\u001b[38;5;28mself\u001b[39m) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    130\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Process the data.\"\"\"\u001b[39;00m\n\u001b[0;32m--> 131\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list \u001b[38;5;241m=\u001b[39m [\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpre_transform\u001b[49m\u001b[43m(\u001b[49m\u001b[43md\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list]\n\u001b[1;32m    133\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data, \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mslices \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mcollate(\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdata_list)\n\u001b[1;32m    134\u001b[0m     \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_data_list \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m  \u001b[38;5;66;03m# Reset cache.\u001b[39;00m\n",
      "File \u001b[0;32m~/anaconda3/envs/virtu-stent/lib/python3.11/site-packages/torch_geometric/transforms/base_transform.py:32\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Shallow-copy the data so that we prevent in-place data modification.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/virtu-stent/lib/python3.11/site-packages/torch_geometric/transforms/compose.py:24\u001b[0m, in \u001b[0;36mCompose.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     22\u001b[0m         data \u001b[38;5;241m=\u001b[39m [transform(d) \u001b[38;5;28;01mfor\u001b[39;00m d \u001b[38;5;129;01min\u001b[39;00m data]\n\u001b[1;32m     23\u001b[0m     \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m---> 24\u001b[0m         data \u001b[38;5;241m=\u001b[39m \u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "File \u001b[0;32m~/anaconda3/envs/virtu-stent/lib/python3.11/site-packages/torch_geometric/transforms/base_transform.py:32\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Shallow-copy the data so that we prevent in-place data modification.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UTWENTE/Projects/challenge-icml-2024/modules/transforms/data_transform.py:76\u001b[0m, in \u001b[0;36mDataTransform.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     63\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: torch_geometric\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mData) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch_geometric\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mData:\n\u001b[1;32m     64\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124;03m\"\"\"Forward pass of the lifting.\u001b[39;00m\n\u001b[1;32m     65\u001b[0m \n\u001b[1;32m     66\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     74\u001b[0m \u001b[38;5;124;03m        The lifted data.\u001b[39;00m\n\u001b[1;32m     75\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mtransform\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/virtu-stent/lib/python3.11/site-packages/torch_geometric/transforms/base_transform.py:32\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Shallow-copy the data so that we prevent in-place data modification.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UTWENTE/Projects/challenge-icml-2024/modules/transforms/liftings/lifting.py:63\u001b[0m, in \u001b[0;36mAbstractLifting.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     61\u001b[0m initial_data \u001b[38;5;241m=\u001b[39m data\u001b[38;5;241m.\u001b[39mto_dict()\n\u001b[1;32m     62\u001b[0m lifted_topology \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mlift_topology(data)\n\u001b[0;32m---> 63\u001b[0m lifted_topology \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfeature_lifting\u001b[49m\u001b[43m(\u001b[49m\u001b[43mlifted_topology\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m     64\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m torch_geometric\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mData(\u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39minitial_data, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mlifted_topology)\n",
      "File \u001b[0;32m~/anaconda3/envs/virtu-stent/lib/python3.11/site-packages/torch_geometric/transforms/base_transform.py:32\u001b[0m, in \u001b[0;36mBaseTransform.__call__\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     30\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21m__call__\u001b[39m(\u001b[38;5;28mself\u001b[39m, data: Any) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Any:\n\u001b[1;32m     31\u001b[0m     \u001b[38;5;66;03m# Shallow-copy the data so that we prevent in-place data modification.\u001b[39;00m\n\u001b[0;32m---> 32\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mcopy\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mcopy\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UTWENTE/Projects/challenge-icml-2024/modules/transforms/feature_liftings/feature_liftings.py:56\u001b[0m, in \u001b[0;36mProjectionSum.forward\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     41\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\n\u001b[1;32m     42\u001b[0m     \u001b[38;5;28mself\u001b[39m, data: torch_geometric\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mData \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m\n\u001b[1;32m     43\u001b[0m ) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m torch_geometric\u001b[38;5;241m.\u001b[39mdata\u001b[38;5;241m.\u001b[39mData \u001b[38;5;241m|\u001b[39m \u001b[38;5;28mdict\u001b[39m:\n\u001b[1;32m     44\u001b[0m \u001b[38;5;250m    \u001b[39m\u001b[38;5;124mr\u001b[39m\u001b[38;5;124;03m\"\"\"Applies the lifting to the input data.\u001b[39;00m\n\u001b[1;32m     45\u001b[0m \n\u001b[1;32m     46\u001b[0m \u001b[38;5;124;03m    Parameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     54\u001b[0m \u001b[38;5;124;03m        The lifted data.\u001b[39;00m\n\u001b[1;32m     55\u001b[0m \u001b[38;5;124;03m    \"\"\"\u001b[39;00m\n\u001b[0;32m---> 56\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mlift_features\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdata\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Documents/UTWENTE/Projects/challenge-icml-2024/modules/transforms/feature_liftings/feature_liftings.py:34\u001b[0m, in \u001b[0;36mProjectionSum.lift_features\u001b[0;34m(self, data)\u001b[0m\n\u001b[1;32m     32\u001b[0m \u001b[38;5;28;01mfor\u001b[39;00m elem \u001b[38;5;129;01min\u001b[39;00m keys:\n\u001b[1;32m     33\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00melem\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m data:\n\u001b[0;32m---> 34\u001b[0m         idx_to_project \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m0\u001b[39m \u001b[38;5;28;01mif\u001b[39;00m elem \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mhyperedges\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28;43mint\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43melem\u001b[49m\u001b[43m)\u001b[49m \u001b[38;5;241m-\u001b[39m \u001b[38;5;241m1\u001b[39m\n\u001b[1;32m     35\u001b[0m         data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m elem] \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39mmatmul(\n\u001b[1;32m     36\u001b[0m             \u001b[38;5;28mabs\u001b[39m(data[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mincidence_\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;241m+\u001b[39m elem]\u001b[38;5;241m.\u001b[39mt()),\n\u001b[1;32m     37\u001b[0m             data[\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mx_\u001b[39m\u001b[38;5;132;01m{\u001b[39;00midx_to_project\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m],\n\u001b[1;32m     38\u001b[0m         )\n\u001b[1;32m     39\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m data\n",
      "\u001b[0;31mValueError\u001b[0m: invalid literal for int() with base 10: 'edges'"
     ]
    }
   ],
   "source": [
    "lifted_dataset = PreProcessor(dataset, transform_config, loader.data_dir)\n",
    "describe_data(lifted_dataset)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create and Run a Simplicial NN Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this section a simple model is created to test that the used lifting works as intended. In this case the model uses the `up_laplacian_1` and the `down_laplacian_1` so the lifting should make sure to add them to the data."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Model configuration for simplicial SAN:\n",
      "\n",
      "{'in_channels': None,\n",
      " 'hidden_channels': 32,\n",
      " 'out_channels': None,\n",
      " 'n_layers': 2,\n",
      " 'n_filters': 2,\n",
      " 'order_harmonic': 5,\n",
      " 'epsilon_harmonic': 0.1}\n"
     ]
    }
   ],
   "source": [
    "from modules.models.simplicial.san import SANModel\n",
    "\n",
    "model_type = \"simplicial\"\n",
    "model_id = \"san\"\n",
    "model_config = load_model_config(model_type, model_id)\n",
    "\n",
    "model = SANModel(model_config, dataset_config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_hat = model(lifted_dataset.get(0))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If everything is correct the cell above should execute without errors. "
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "venv_topox",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.7"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
